{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qVkFufEy8SN-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "fmnist = tf.keras.datasets.fashion_mnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = fmnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvHWvxaw8X25",
        "outputId": "64a84dc8-4ac2-4cef-9620-5404eb12889b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5SaJMzR8noQ",
        "outputId": "fd7fabd6-b900-4c20-81c7-3dd920004d7d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nPLN8PN8pAw",
        "outputId": "24091cc3-64ab-4b17-cc4c-f173a31149ee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_images, test_images = train_images/255.0, test_images / 255.0"
      ],
      "metadata": {
        "id": "udm6QvqW8qyR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten"
      ],
      "metadata": {
        "id": "K_CJ8Vo78sbA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  model = Sequential([\n",
        "      Flatten(input_shape = (28, 28)),\n",
        "      Dense(100, activation=\"relu\"),\n",
        "      Dense(100, activation=\"relu\"),\n",
        "      Dense(10, activation = 'softmax')\n",
        "  ])\n",
        "  return model"
      ],
      "metadata": {
        "id": "7ibgdWqd818Y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zy3nF5WJ9IVK",
        "outputId": "91d81742-94fb-4526-c068-36ef96aa18f7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 89610 (350.04 KB)\n",
            "Trainable params: 89610 (350.04 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(\n",
        "    optimizer = sgd,\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "VNhrmN_39OPv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = model.fit(train_images, train_labels, epochs=20,\n",
        "              validation_split=0.2, batch_size = 64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IjmiDhP9fTH",
        "outputId": "5df2c618-47cf-4c29-801c-830dd0bae477"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.9953 - accuracy: 0.6827 - val_loss: 0.6658 - val_accuracy: 0.7789\n",
            "Epoch 2/20\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.5980 - accuracy: 0.7963 - val_loss: 0.5551 - val_accuracy: 0.8108\n",
            "Epoch 3/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.5239 - accuracy: 0.8207 - val_loss: 0.5054 - val_accuracy: 0.8240\n",
            "Epoch 4/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4871 - accuracy: 0.8311 - val_loss: 0.4822 - val_accuracy: 0.8294\n",
            "Epoch 5/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4621 - accuracy: 0.8392 - val_loss: 0.4576 - val_accuracy: 0.8381\n",
            "Epoch 6/20\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.4440 - accuracy: 0.8456 - val_loss: 0.4583 - val_accuracy: 0.8376\n",
            "Epoch 7/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4296 - accuracy: 0.8486 - val_loss: 0.4375 - val_accuracy: 0.8491\n",
            "Epoch 8/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4166 - accuracy: 0.8549 - val_loss: 0.4250 - val_accuracy: 0.8527\n",
            "Epoch 9/20\n",
            "750/750 [==============================] - 3s 5ms/step - loss: 0.4073 - accuracy: 0.8579 - val_loss: 0.4143 - val_accuracy: 0.8559\n",
            "Epoch 10/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.3981 - accuracy: 0.8603 - val_loss: 0.4028 - val_accuracy: 0.8593\n",
            "Epoch 11/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.3902 - accuracy: 0.8633 - val_loss: 0.3993 - val_accuracy: 0.8618\n",
            "Epoch 12/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.3829 - accuracy: 0.8668 - val_loss: 0.3971 - val_accuracy: 0.8629\n",
            "Epoch 13/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.3776 - accuracy: 0.8672 - val_loss: 0.3949 - val_accuracy: 0.8606\n",
            "Epoch 14/20\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.3701 - accuracy: 0.8696 - val_loss: 0.3878 - val_accuracy: 0.8650\n",
            "Epoch 15/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.3656 - accuracy: 0.8716 - val_loss: 0.3862 - val_accuracy: 0.8660\n",
            "Epoch 16/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.3604 - accuracy: 0.8734 - val_loss: 0.3826 - val_accuracy: 0.8636\n",
            "Epoch 17/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.3554 - accuracy: 0.8745 - val_loss: 0.3792 - val_accuracy: 0.8658\n",
            "Epoch 18/20\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.3502 - accuracy: 0.8762 - val_loss: 0.3781 - val_accuracy: 0.8679\n",
            "Epoch 19/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.3452 - accuracy: 0.8785 - val_loss: 0.3729 - val_accuracy: 0.8705\n",
            "Epoch 20/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.3413 - accuracy: 0.8795 - val_loss: 0.3685 - val_accuracy: 0.8709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.01\n",
        "epoch = 20\n",
        "decay = 0.01\n",
        "def time_decay(epoch, lr, decay = 0.01):\n",
        "  return lr / (1 + decay * epoch)"
      ],
      "metadata": {
        "id": "_mMnLStk9haw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgd = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(\n",
        "    optimizer = sgd,\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "FA5fVDVTKCTB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = model.fit(train_images, train_labels, epochs=20,\n",
        "              validation_split=0.2, batch_size = 64,\n",
        "              callbacks =[tf.keras.callbacks.LearningRateScheduler(time_decay, verbose = 1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5A97IWKoKXcT",
        "outputId": "5770190f-dbfe-4537-df46-130b319ea7bc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/20\n",
            "750/750 [==============================] - 4s 4ms/step - loss: 0.3053 - accuracy: 0.8908 - val_loss: 0.3442 - val_accuracy: 0.8812 - lr: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009900989877705527.\n",
            "Epoch 2/20\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.3020 - accuracy: 0.8913 - val_loss: 0.3502 - val_accuracy: 0.8758 - lr: 0.0099\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009706852884561407.\n",
            "Epoch 3/20\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.2988 - accuracy: 0.8936 - val_loss: 0.3398 - val_accuracy: 0.8796 - lr: 0.0097\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009424129085054675.\n",
            "Epoch 4/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.2959 - accuracy: 0.8937 - val_loss: 0.3415 - val_accuracy: 0.8789 - lr: 0.0094\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009061662981716486.\n",
            "Epoch 5/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.2934 - accuracy: 0.8946 - val_loss: 0.3366 - val_accuracy: 0.8832 - lr: 0.0091\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.008630155630054927.\n",
            "Epoch 6/20\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.2904 - accuracy: 0.8955 - val_loss: 0.3386 - val_accuracy: 0.8813 - lr: 0.0086\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.008141656212930408.\n",
            "Epoch 7/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.2870 - accuracy: 0.8971 - val_loss: 0.3367 - val_accuracy: 0.8812 - lr: 0.0081\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.007609024678713807.\n",
            "Epoch 8/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.2843 - accuracy: 0.8970 - val_loss: 0.3366 - val_accuracy: 0.8831 - lr: 0.0076\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.007045393188794454.\n",
            "Epoch 9/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.2820 - accuracy: 0.8975 - val_loss: 0.3382 - val_accuracy: 0.8819 - lr: 0.0070\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.006463663618362278.\n",
            "Epoch 10/20\n",
            "750/750 [==============================] - 5s 6ms/step - loss: 0.2793 - accuracy: 0.9002 - val_loss: 0.3369 - val_accuracy: 0.8823 - lr: 0.0065\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.005876057865944776.\n",
            "Epoch 11/20\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.2771 - accuracy: 0.9003 - val_loss: 0.3340 - val_accuracy: 0.8831 - lr: 0.0059\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.005293745748900078.\n",
            "Epoch 12/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.2743 - accuracy: 0.9015 - val_loss: 0.3419 - val_accuracy: 0.8804 - lr: 0.0053\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.004726558524583067.\n",
            "Epoch 13/20\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.2722 - accuracy: 0.9022 - val_loss: 0.3318 - val_accuracy: 0.8835 - lr: 0.0047\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.0041827950956283425.\n",
            "Epoch 14/20\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.2703 - accuracy: 0.9024 - val_loss: 0.3329 - val_accuracy: 0.8819 - lr: 0.0042\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.0036691184760185708.\n",
            "Epoch 15/20\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.2686 - accuracy: 0.9035 - val_loss: 0.3308 - val_accuracy: 0.8829 - lr: 0.0037\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.0031905378336491794.\n",
            "Epoch 16/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.2673 - accuracy: 0.9044 - val_loss: 0.3300 - val_accuracy: 0.8839 - lr: 0.0032\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.0027504637195118545.\n",
            "Epoch 17/20\n",
            "750/750 [==============================] - 4s 6ms/step - loss: 0.2661 - accuracy: 0.9038 - val_loss: 0.3276 - val_accuracy: 0.8845 - lr: 0.0028\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.0023508237467871774.\n",
            "Epoch 18/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.2646 - accuracy: 0.9051 - val_loss: 0.3292 - val_accuracy: 0.8852 - lr: 0.0024\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.001992223492302632.\n",
            "Epoch 19/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.2638 - accuracy: 0.9055 - val_loss: 0.3289 - val_accuracy: 0.8844 - lr: 0.0020\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.0016741374382326583.\n",
            "Epoch 20/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.2627 - accuracy: 0.9059 - val_loss: 0.3281 - val_accuracy: 0.8856 - lr: 0.0017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def step_decay(epochs, lr):\n",
        "  drop_rate = 0.5\n",
        "  epoch_step = 5\n",
        "  return lr * math.pow(drop_rate, math.floor(epochs / epoch_step))"
      ],
      "metadata": {
        "id": "pzyEpk3tKkMd"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "sgd = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(\n",
        "    optimizer = sgd,\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "h = model.fit(train_images, train_labels, epochs=20,\n",
        "              validation_split=0.2, batch_size = 64,\n",
        "              callbacks =[tf.keras.callbacks.LearningRateScheduler(step_decay, verbose = 1)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_8Xo6VKMdoE",
        "outputId": "946530a1-12a7-44d4-be50-3a36372a2e6c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/20\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 1.0021 - accuracy: 0.6782 - val_loss: 0.6704 - val_accuracy: 0.7651 - lr: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 2/20\n",
            "750/750 [==============================] - 3s 5ms/step - loss: 0.6016 - accuracy: 0.7949 - val_loss: 0.5507 - val_accuracy: 0.8119 - lr: 0.0100\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 3/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.5276 - accuracy: 0.8209 - val_loss: 0.5038 - val_accuracy: 0.8263 - lr: 0.0100\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 4/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4905 - accuracy: 0.8309 - val_loss: 0.4903 - val_accuracy: 0.8277 - lr: 0.0100\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 5/20\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.4659 - accuracy: 0.8390 - val_loss: 0.4653 - val_accuracy: 0.8348 - lr: 0.0100\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.004999999888241291.\n",
            "Epoch 6/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4437 - accuracy: 0.8470 - val_loss: 0.4467 - val_accuracy: 0.8410 - lr: 0.0050\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0024999999441206455.\n",
            "Epoch 7/20\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.4336 - accuracy: 0.8510 - val_loss: 0.4430 - val_accuracy: 0.8427 - lr: 0.0025\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0012499999720603228.\n",
            "Epoch 8/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4290 - accuracy: 0.8523 - val_loss: 0.4402 - val_accuracy: 0.8451 - lr: 0.0012\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0006249999860301614.\n",
            "Epoch 9/20\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.4269 - accuracy: 0.8534 - val_loss: 0.4390 - val_accuracy: 0.8443 - lr: 6.2500e-04\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.0003124999930150807.\n",
            "Epoch 10/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4258 - accuracy: 0.8536 - val_loss: 0.4382 - val_accuracy: 0.8452 - lr: 3.1250e-04\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 7.812499825377017e-05.\n",
            "Epoch 11/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4252 - accuracy: 0.8534 - val_loss: 0.4381 - val_accuracy: 0.8447 - lr: 7.8125e-05\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 1.9531249563442543e-05.\n",
            "Epoch 12/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4250 - accuracy: 0.8536 - val_loss: 0.4381 - val_accuracy: 0.8446 - lr: 1.9531e-05\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 4.882812390860636e-06.\n",
            "Epoch 13/20\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.4250 - accuracy: 0.8536 - val_loss: 0.4381 - val_accuracy: 0.8447 - lr: 4.8828e-06\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 1.220703097715159e-06.\n",
            "Epoch 14/20\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.4250 - accuracy: 0.8536 - val_loss: 0.4381 - val_accuracy: 0.8447 - lr: 1.2207e-06\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 3.0517577442878974e-07.\n",
            "Epoch 15/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4250 - accuracy: 0.8536 - val_loss: 0.4381 - val_accuracy: 0.8447 - lr: 3.0518e-07\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 3.814697180359872e-08.\n",
            "Epoch 16/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4250 - accuracy: 0.8536 - val_loss: 0.4381 - val_accuracy: 0.8447 - lr: 3.8147e-08\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 4.76837147544984e-09.\n",
            "Epoch 17/20\n",
            "750/750 [==============================] - 4s 6ms/step - loss: 0.4250 - accuracy: 0.8536 - val_loss: 0.4381 - val_accuracy: 0.8447 - lr: 4.7684e-09\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 5.9604643443123e-10.\n",
            "Epoch 18/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4250 - accuracy: 0.8536 - val_loss: 0.4381 - val_accuracy: 0.8447 - lr: 5.9605e-10\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 7.450580430390374e-11.\n",
            "Epoch 19/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4250 - accuracy: 0.8536 - val_loss: 0.4381 - val_accuracy: 0.8447 - lr: 7.4506e-11\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 9.313225537987968e-12.\n",
            "Epoch 20/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4250 - accuracy: 0.8536 - val_loss: 0.4381 - val_accuracy: 0.8447 - lr: 9.3132e-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def exp_decay(epoch, lr):\n",
        "  k = 0.1\n",
        "  return lr * math.exp(-k * epoch)"
      ],
      "metadata": {
        "id": "ogqhJWrPNvdk"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model()\n",
        "sgd = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(\n",
        "    optimizer = sgd,\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "h = model.fit(train_images, train_labels, epochs=20,\n",
        "              validation_split=0.2, batch_size = 64,\n",
        "              callbacks =[tf.keras.callbacks.LearningRateScheduler(exp_decay, verbose = 1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfDly69kPbCv",
        "outputId": "25df77a1-9ac2-49a3-ed2b-ced389f3f656"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.009999999776482582.\n",
            "Epoch 1/20\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 1.0152 - accuracy: 0.6785 - val_loss: 0.6544 - val_accuracy: 0.7810 - lr: 0.0100\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.009048373978112673.\n",
            "Epoch 2/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.6056 - accuracy: 0.7947 - val_loss: 0.5570 - val_accuracy: 0.8129 - lr: 0.0090\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.007408182361869137.\n",
            "Epoch 3/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.5361 - accuracy: 0.8176 - val_loss: 0.5142 - val_accuracy: 0.8247 - lr: 0.0074\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.005488116309006892.\n",
            "Epoch 4/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.5029 - accuracy: 0.8278 - val_loss: 0.5065 - val_accuracy: 0.8272 - lr: 0.0055\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0036787943669406103.\n",
            "Epoch 5/20\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.4849 - accuracy: 0.8342 - val_loss: 0.4866 - val_accuracy: 0.8295 - lr: 0.0037\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.002231301504463931.\n",
            "Epoch 6/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4743 - accuracy: 0.8358 - val_loss: 0.4782 - val_accuracy: 0.8371 - lr: 0.0022\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0012245642306654484.\n",
            "Epoch 7/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4684 - accuracy: 0.8383 - val_loss: 0.4739 - val_accuracy: 0.8380 - lr: 0.0012\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0006081006210128147.\n",
            "Epoch 8/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4652 - accuracy: 0.8395 - val_loss: 0.4732 - val_accuracy: 0.8384 - lr: 6.0810e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0002732372189878032.\n",
            "Epoch 9/20\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.4637 - accuracy: 0.8404 - val_loss: 0.4716 - val_accuracy: 0.8383 - lr: 2.7324e-04\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.00011108995893017247.\n",
            "Epoch 10/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4630 - accuracy: 0.8410 - val_loss: 0.4713 - val_accuracy: 0.8388 - lr: 1.1109e-04\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 4.0867712823065846e-05.\n",
            "Epoch 11/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4627 - accuracy: 0.8408 - val_loss: 0.4712 - val_accuracy: 0.8392 - lr: 4.0868e-05\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 1.360367941682613e-05.\n",
            "Epoch 12/20\n",
            "750/750 [==============================] - 3s 3ms/step - loss: 0.4626 - accuracy: 0.8406 - val_loss: 0.4712 - val_accuracy: 0.8389 - lr: 1.3604e-05\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 4.097349583419071e-06.\n",
            "Epoch 13/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4625 - accuracy: 0.8409 - val_loss: 0.4712 - val_accuracy: 0.8389 - lr: 4.0973e-06\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 1.1166580261696665e-06.\n",
            "Epoch 14/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4625 - accuracy: 0.8409 - val_loss: 0.4712 - val_accuracy: 0.8389 - lr: 1.1167e-06\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 2.7536448259777863e-07.\n",
            "Epoch 15/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4625 - accuracy: 0.8409 - val_loss: 0.4712 - val_accuracy: 0.8389 - lr: 2.7536e-07\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 6.144211846453306e-08.\n",
            "Epoch 16/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4625 - accuracy: 0.8409 - val_loss: 0.4712 - val_accuracy: 0.8389 - lr: 6.1442e-08\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 1.2404949156575967e-08.\n",
            "Epoch 17/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4625 - accuracy: 0.8409 - val_loss: 0.4712 - val_accuracy: 0.8389 - lr: 1.2405e-08\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 2.2661798114290247e-09.\n",
            "Epoch 18/20\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.4625 - accuracy: 0.8409 - val_loss: 0.4712 - val_accuracy: 0.8389 - lr: 2.2662e-09\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 3.745970196980421e-10.\n",
            "Epoch 19/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4625 - accuracy: 0.8409 - val_loss: 0.4712 - val_accuracy: 0.8389 - lr: 3.7460e-10\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 5.6027959056738765e-11.\n",
            "Epoch 20/20\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.4625 - accuracy: 0.8409 - val_loss: 0.4712 - val_accuracy: 0.8389 - lr: 5.6028e-11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HrdclUQ1PhW7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}